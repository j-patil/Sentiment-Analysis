import java.io.FileInputStream;
import java.io.IOException;
import java.io.InputStream;
import java.util.ArrayList;
import java.util.HashSet;
import java.util.Scanner;
import java.util.Set;
import java.util.StringTokenizer;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Mapper.Context;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.KeyValueTextInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

import opennlp.tools.sentdetect.SentenceDetectorME;
import opennlp.tools.sentdetect.SentenceModel;

public class StopWordsRemover {

	public static class KeyMapper extends Mapper<Text,Text,Text,Text> {
        
		private Text OutputKey = new Text();
		private Text OutputValue = new Text();
		
		public static String[] sentenceDetect (String input) throws IOException{
			InputStream modelIn = new FileInputStream("lib/en-sent.bin");
			SentenceModel model = new SentenceModel(modelIn);
			if (modelIn != null)  
				modelIn.close(); 
			
			SentenceDetectorME sentenceDetector = new SentenceDetectorME(model);
	        String sentences[] = sentenceDetector.sentDetect(input);
	        return sentences;
		}

		/*public static void checker (String i,String o) throws IOException{
			
	        ArrayList<String> wordsList = new ArrayList<String>();
		    HashSet<String> stopWordsSet = new HashSet<String>();
		    
		    Scanner sc = new Scanner(new File("src/Stopword.txt"));
		    while (sc.hasNext()) {
		    	stopWordsSet.add(sc.next());
		    }
		    sc.close();
		    
	        String input,store =" ";
	        
	        while ((input = br.readLine()) != null)
	        {
	        	String alpha= input.trim().replaceAll("[^a-zA-Z0-9\\s]", "").replaceAll("\\s+", " "); //Punctuation are removed here
				String[] words = alpha.split(" ");
		    	
			    for(String word : words) {
			    String wordCompare = word.toLowerCase();
			    if(!stopWordsSet.contains(wordCompare))
			    wordsList.add(word);
			    }
			    
			    for (String str : wordsList) {
			    	store += str+" ";
			    }		    
			    bw.write(store);	
			    bw.newLine();
			    store = " ";
			    wordsList.clear();
	        }
	        
		    br.close();
			bw.close();
			
			System.out.println("Done");
			}*/
		
		public void map(Text key, Text values, Context context) throws IOException, InterruptedException {	
			String val = "";
			String sentence[];
			val = values.toString();
			sentence = sentenceDetect(val);
			for (String s : sentence) {
				OutputKey.set(key);
				OutputValue.set(s);
				context.write(OutputKey, OutputValue);
			}
		}
		
    }
	
	public static void main(String[] args) {
    	try {
        Configuration conf = new Configuration();
        Job job = Job.getInstance(conf,"Task 2");
        job.setJarByClass(MapReduceTwo.class);
        job.setMapperClass(KeyMapper.class);
        job.setReducerClass(KeyReducer.class);
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(Text.class);
        job.setInputFormatClass(KeyValueTextInputFormat.class);
        FileInputFormat.addInputPath(job, new Path(args[0]));
        FileOutputFormat.setOutputPath(job, new Path(args[1]));
        System.exit(job.waitForCompletion(true) ? 0 : 1);
    	}
    	catch (IOException e) {
    		System.out.print(e);
    	}
    	catch (InterruptedException e) {
    		System.out.print(e);
    	}
    	catch (ClassNotFoundException e) {
    		System.out.print(e);
    	}
    	}

}
